{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqb9balwIb7/ImIgCUq//l"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Maximum Marginal Retrivers (MMR)"
      ],
      "metadata": {
        "id": "iC8M2hYglcPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-community langchain-huggingface faiss-cpu"
      ],
      "metadata": {
        "id": "ATGo4RQPmlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document = [\n",
        "    Document(page_content=\"Langchain makes it easy to work with LLMs\"),\n",
        "    Document(page_content=\"Langchain is used to build LLM based Applications\"),\n",
        "    Document(page_content=\"Chroma is used to store and search document embeddings\"),\n",
        "    Document(page_content=\"Embeddings are vector representations of text\"),\n",
        "    Document(page_content=\"MMR helps you get diverse result when doing similarity search\"),\n",
        "    Document(page_content=\"Lanchain supports chroma, FAISS, Pinecone, and more\"),\n",
        "]\n",
        "\n",
        "EmbeddingModels = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "VectorStore = FAISS.from_documents(\n",
        "    documents= document,\n",
        "    embedding= EmbeddingModels\n",
        "    )"
      ],
      "metadata": {
        "id": "gHDZ376XlVDc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = VectorStore.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 3, \"lambda_mult\":0.5}\n",
        ")"
      ],
      "metadata": {
        "id": "hw2FddRfmahQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Langchain?\"\n",
        "result = retriever.invoke(query)"
      ],
      "metadata": {
        "id": "ijaq9mCDorxl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, document in enumerate(result):\n",
        "    print(f\"{i + 1}. {document.page_content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nwpl-2wo4wE",
        "outputId": "fa8d42dd-9b90-43e5-f040-29b26e16a57d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Langchain is used to build LLM based Applications\n",
            "2. Lanchain supports chroma, FAISS, Pinecone, and more\n",
            "3. Embeddings are vector representations of text\n"
          ]
        }
      ]
    }
  ]
}